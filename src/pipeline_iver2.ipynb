{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import h2o\n",
    "import os\n",
    "import pandas as pd\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# from .feature_engineering_filter import Find_correct_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../Datasets/ais_train.csv\", delimiter=\"|\")\n",
    "test_data = pd.read_csv(\"../Datasets/ais_test.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vessel_data = pd.read_csv(\"../Datasets/vessels.csv\", delimiter=\"|\")\n",
    "port_data = pd.read_csv(\"../Datasets/ports.csv\", delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"time\"] = pd.to_datetime(train_data[\"time\"])\n",
    "test_data[\"time\"] = pd.to_datetime(test_data[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_data=train_data.merge(vessel_data[['vesselId', 'shippingLineId']], on='vesselId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_data_renamed=pd.DataFrame()\n",
    "port_data_renamed[[\"portId\",\"port_latitude\",\"port_longitude\"]]=port_data[[\"portId\",\"latitude\",\"longitude\"]]\n",
    "train_data=train_data.merge(port_data_renamed, on=\"portId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'cog', 'sog', 'rot', 'heading', 'navstat', 'etaRaw', 'latitude',\n",
      "       'longitude', 'vesselId', 'portId', 'port_latitude', 'port_longitude'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time    cog   sog  rot  heading  navstat       etaRaw  \\\n",
      "0 2024-01-01 00:00:25  284.0   0.7  0.0     88.0        0  01-09 23:00   \n",
      "1 2024-01-01 00:00:36  109.6   0.0 -6.0    347.0        1  12-29 20:00   \n",
      "2 2024-01-01 00:01:45  111.0  11.0  0.0    112.0        0  01-02 09:00   \n",
      "3 2024-01-01 00:03:11   96.4   0.0  0.0    142.0        1  12-31 20:00   \n",
      "4 2024-01-01 00:03:51  214.0  19.7  0.0    215.0        0  01-25 12:00   \n",
      "\n",
      "   latitude  longitude                  vesselId                    portId  \\\n",
      "0 -34.74370  -57.85130  61e9f3a8b937134a3c4bfdf7  61d371c43aeaecc07011a37f   \n",
      "1   8.89440  -79.47939  61e9f3d4b937134a3c4bff1f  634c4de270937fc01c3a7689   \n",
      "2  39.19065  -76.47567  61e9f436b937134a3c4c0131  61d3847bb7b7526e1adf3d19   \n",
      "3 -34.41189  151.02067  61e9f3b4b937134a3c4bfe77  61d36f770a1807568ff9a126   \n",
      "4  35.88379   -5.91636  61e9f41bb937134a3c4c0087  634c4de270937fc01c3a74f3   \n",
      "\n",
      "   port_latitude  port_longitude  \n",
      "0       -33.5875      -71.618889  \n",
      "1         8.9670      -79.533000  \n",
      "2        39.2325      -76.558889  \n",
      "3       -34.4625      150.899444  \n",
      "4        35.7830       -5.817000  \n",
      "                 time    cog   sog  rot  heading  navstat       etaRaw  \\\n",
      "0 2024-01-12 14:07:47  308.1  17.1 -6.0    316.0        0  01-08 06:00   \n",
      "1 2024-01-12 14:31:00  307.6  17.3  5.0    313.0        0  01-14 23:30   \n",
      "2 2024-01-12 14:57:23  306.8  16.9  5.0    312.0        0  01-14 23:30   \n",
      "3 2024-01-12 15:18:48  307.9  16.9  6.0    313.0        0  01-14 23:30   \n",
      "4 2024-01-12 15:39:47  307.0  16.3  7.0    313.0        0  01-14 23:30   \n",
      "\n",
      "   latitude  longitude                  vesselId                    portId  \\\n",
      "0   7.50361   77.58340  61e9f38eb937134a3c4bfd8b  61d376b393c6feb83e5eb50c   \n",
      "1   7.57302   77.49505  61e9f38eb937134a3c4bfd8b  61d376d893c6feb83e5eb546   \n",
      "2   7.65043   77.39404  61e9f38eb937134a3c4bfd8b  61d376d893c6feb83e5eb546   \n",
      "3   7.71275   77.31394  61e9f38eb937134a3c4bfd8b  61d376d893c6feb83e5eb546   \n",
      "4   7.77191   77.23585  61e9f38eb937134a3c4bfd8b  61d376d893c6feb83e5eb546   \n",
      "\n",
      "   port_latitude  port_longitude  \n",
      "0      13.263333       80.341111  \n",
      "1      18.941944       72.885278  \n",
      "2      18.941944       72.885278  \n",
      "3      18.941944       72.885278  \n",
      "4      18.941944       72.885278  \n"
     ]
    }
   ],
   "source": [
    "train_data_preprocessed = train_data\n",
    "train_data_preprocessed.loc[train_data_preprocessed[\"cog\"] >= 360, \"cog\"] = np.nan\n",
    "train_data_preprocessed.loc[train_data_preprocessed[\"sog\"] >= 1023, \"sog\"] = np.nan\n",
    "train_data_preprocessed.loc[train_data_preprocessed[\"rot\"] == -128, \"rot\"] = np.nan\n",
    "train_data_preprocessed.loc[train_data_preprocessed[\"heading\"] == 511, \"heading\"] = (\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "\n",
    "pattern = r\"^\\d{2}-\\d{2} \\d{2}:\\d{2}$\"\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].where(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.match(pattern, na=False), np.nan\n",
    ")\n",
    "\n",
    "\n",
    "train_data_preprocessed = train_data_preprocessed.sort_values(\"time\")\n",
    "\n",
    "print(train_data_preprocessed.head())\n",
    "\n",
    "\n",
    "train_data_preprocessed = (\n",
    "    train_data_preprocessed.groupby(\"vesselId\")\n",
    "    .apply(lambda group: group.ffill().bfill())\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "print(train_data_preprocessed.head())\n",
    "\n",
    "train_data_preprocessed[\"heading\"] = train_data_preprocessed[\"heading\"].fillna(0)\n",
    "\n",
    "train_data_preprocessed = train_data_preprocessed.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Replace '00-' in etaRaw with the corresponding month and day from the 'time' column\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].mask(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.contains(\"00-\", na=False),\n",
    "    \"01\" + train_data_preprocessed[\"etaRaw\"].str[2:],\n",
    ")\n",
    "\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].mask(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.contains(\"-00\", na=False),\n",
    "    train_data_preprocessed[\"etaRaw\"].str[:2]\n",
    "    + \"-01\"\n",
    "    + train_data_preprocessed[\"etaRaw\"].str[5:],\n",
    ")\n",
    "\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].mask(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.contains(\":60\", na=False),\n",
    "    train_data_preprocessed[\"etaRaw\"].str[:9] + \"59\",\n",
    ")\n",
    "\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].mask(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.contains(\"60:\", na=False),\n",
    "    train_data_preprocessed[\"etaRaw\"].str[:6] + \"01:00\",\n",
    ")\n",
    "\n",
    "train_data_preprocessed[\"etaRaw\"] = train_data_preprocessed[\"etaRaw\"].mask(\n",
    "    train_data_preprocessed[\"etaRaw\"].str.contains(\"24:\", na=False),\n",
    "    train_data_preprocessed[\"etaRaw\"].str[:6] + \"23:59\",\n",
    ")\n",
    "\n",
    "\n",
    "train_data_preprocessed[\"etaRaw\"] = pd.to_datetime(\n",
    "    train_data_preprocessed[\"time\"].dt.year.astype(str)\n",
    "    + \"-\"\n",
    "    + train_data_preprocessed[\"etaRaw\"]\n",
    "    + \":00\",\n",
    "    format=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "\n",
    "train_data_preprocessed[\"seconds_to_eta\"] = (\n",
    "    train_data_preprocessed[\"etaRaw\"] - train_data_preprocessed[\"time\"]\n",
    ").dt.total_seconds()\n",
    "\n",
    "train_data_preprocessed = train_data_preprocessed.drop(columns=[\"etaRaw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'vesselId', 'seconds_to_eta', 'latitude_sin', 'latitude_cos',\n",
      "       'longitude_sin', 'longitude_cos', 'port_latitude_sin',\n",
      "       'port_latitude_cos', 'port_longitude_sin', 'port_longitude_cos',\n",
      "       'cog_sog_sin', 'cog_sog_cos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_latitude_radians = np.deg2rad(train_data_preprocessed[\"latitude\"])\n",
    "train_longitude_radians = np.deg2rad(train_data_preprocessed[\"longitude\"])\n",
    "train_cog_radians = np.deg2rad(train_data_preprocessed[\"cog\"])\n",
    "train_heading_radians = np.deg2rad(train_data_preprocessed[\"heading\"])\n",
    "\n",
    "port_latitude_radians = np.deg2rad(train_data_preprocessed[\"port_latitude\"])\n",
    "port_longitude_radians = np.deg2rad(train_data_preprocessed[\"port_longitude\"])\n",
    "\n",
    "train_hour = np.deg2rad(train_data_preprocessed[\"time\"].dt.hour * 360 / 24)\n",
    "train_day = np.deg2rad(train_data_preprocessed[\"time\"].dt.day * 360 / 30)\n",
    "train_month = np.deg2rad(train_data_preprocessed[\"time\"].dt.month * 360 / 12)\n",
    "\n",
    "\n",
    "train_latitude_sin = np.sin(train_latitude_radians)\n",
    "train_latitude_cos = np.cos(train_latitude_radians)\n",
    "train_longitude_sin = np.sin(train_longitude_radians)\n",
    "train_longitude_cos = np.cos(train_longitude_radians)\n",
    "\n",
    "port_latitude_sin = np.sin(port_latitude_radians)\n",
    "port_latitude_cos = np.cos(port_latitude_radians)\n",
    "port_longitude_sin = np.sin(port_longitude_radians)\n",
    "port_longitude_cos = np.cos(port_longitude_radians)\n",
    "\n",
    "train_cog_sin = np.sin(train_cog_radians)\n",
    "train_cog_cos = np.cos(train_cog_radians)\n",
    "\n",
    "train_heading_sin = np.sin(train_heading_radians)\n",
    "train_heading_cos = np.cos(train_heading_radians)\n",
    "\n",
    "train_hour_sin = np.sin(train_hour)\n",
    "train_hour_cos = np.cos(train_hour)\n",
    "\n",
    "train_day_sin = np.sin(train_day)\n",
    "train_day_cos = np.cos(train_day)\n",
    "\n",
    "train_month_sin = np.sin(train_month)\n",
    "train_month_cos = np.cos(train_month)\n",
    "\n",
    "\n",
    "train_data_preprocessed[\"latitude_sin\"] = train_latitude_sin\n",
    "train_data_preprocessed[\"latitude_cos\"] = train_latitude_cos\n",
    "train_data_preprocessed[\"longitude_sin\"] = train_longitude_sin\n",
    "train_data_preprocessed[\"longitude_cos\"] = train_longitude_cos\n",
    "train_data_preprocessed[\"port_latitude_sin\"] = train_latitude_sin\n",
    "train_data_preprocessed[\"port_latitude_cos\"] = train_latitude_cos\n",
    "train_data_preprocessed[\"port_longitude_sin\"] = train_longitude_sin\n",
    "train_data_preprocessed[\"port_longitude_cos\"] = train_longitude_cos\n",
    "train_data_preprocessed[\"cog_sin\"] = train_cog_sin\n",
    "train_data_preprocessed[\"cog_cos\"] = train_cog_cos\n",
    "train_data_preprocessed[\"heading_sin\"] = train_heading_sin\n",
    "train_data_preprocessed[\"heading_cos\"] = train_heading_cos\n",
    "\n",
    "train_data_preprocessed[\"hour_sin\"] = train_hour_sin\n",
    "train_data_preprocessed[\"hour_cos\"] = train_hour_cos\n",
    "train_data_preprocessed[\"day_sin\"] = train_day_sin\n",
    "train_data_preprocessed[\"day_cos\"] = train_day_cos\n",
    "train_data_preprocessed[\"month_sin\"] = train_month_sin\n",
    "train_data_preprocessed[\"month_cos\"] = train_month_cos\n",
    "\n",
    "\n",
    "train_data_preprocessed[\"cog_sog_sin\"] = train_data_preprocessed[\"cog_sin\"]*train_data_preprocessed[\"sog\"]\n",
    "train_data_preprocessed[\"cog_sog_cos\"] = train_data_preprocessed[\"cog_cos\"]*train_data_preprocessed[\"sog\"]\n",
    "\n",
    "train_data_preprocessed = train_data_preprocessed.drop(\n",
    "    columns=[\"latitude\", \"longitude\", \"cog\", \"heading\", \"portId\",\"cog_sin\",\"cog_cos\",\"sog\",\"port_latitude\",\"port_longitude\",\"hour_sin\",\"hour_cos\",\"day_sin\",\"day_cos\",\"month_sin\",\"month_cos\",\"rot\",\"heading_sin\",\"heading_cos\",\"navstat\"], axis=1\n",
    ")\n",
    "print(train_data_preprocessed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_dataframe(df):\n",
    "        \"\"\"\n",
    "        Downcasts numerical columns to reduce memory usage.\n",
    "        \"\"\"\n",
    "        for col in df.select_dtypes(include=['float64']).columns:\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        for col in df.select_dtypes(include=['int64']).columns:\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        return df\n",
    "\n",
    "train_data_preprocessed = optimize_dataframe(train_data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Last_known_location_training_data(\n",
    "    data: pd.DataFrame, max_shift_lengths, max_instances_per_group=1000\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"_summary_  Groups training data by vesselId, and propogates all data from last known location\n",
    "\n",
    "    Args:\n",
    "    data (_type_): _description_ the data to be altered\n",
    "\n",
    "    Returns:\n",
    "        _type_:? _description_ the altered data\n",
    "\n",
    "    \"\"\"\n",
    "    all_test_data = pd.DataFrame()\n",
    "    shift_length=1\n",
    "    while shift_length<=max_shift_lengths:\n",
    "\n",
    "        grouped_data = data.groupby(\"vesselId\").apply(lambda x: x.sort_values(\"time\"))\n",
    "\n",
    "        grouped_data[\"time_diff\"] = (\n",
    "            grouped_data[\"time\"].diff(-shift_length).dt.total_seconds().abs()\n",
    "        )\n",
    "\n",
    "        original_time_and_id = grouped_data[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"vesselId\",\n",
    "                \"latitude_sin\",\n",
    "                \"latitude_cos\",\n",
    "                \"longitude_sin\",\n",
    "                \"longitude_cos\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        shifted_data = grouped_data.shift(shift_length)\n",
    "        shifted_data[\n",
    "            [\n",
    "                \"last_latitude_sin\",\n",
    "                \"last_latitude_cos\",\n",
    "                \"last_longitude_sin\",\n",
    "                \"last_longitude_cos\",\n",
    "            ]\n",
    "        ] = shifted_data[\n",
    "            [\"latitude_sin\", \"latitude_cos\", \"longitude_sin\", \"longitude_cos\"]\n",
    "        ]\n",
    "\n",
    "        shifted_data[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"vesselId\",\n",
    "                \"latitude_sin\",\n",
    "                \"latitude_cos\",\n",
    "                \"longitude_sin\",\n",
    "                \"longitude_cos\",\n",
    "            ]\n",
    "        ] = original_time_and_id[\n",
    "            [\n",
    "                \"time\",\n",
    "                \"vesselId\",\n",
    "                \"latitude_sin\",\n",
    "                \"latitude_cos\",\n",
    "                \"longitude_sin\",\n",
    "                \"longitude_cos\",\n",
    "            ]\n",
    "        ]\n",
    "        \n",
    "\n",
    "        # Drops all values with nan values\n",
    "        result = shifted_data.dropna().reset_index(drop=True)\n",
    "\n",
    "        # Step 6: Limit to max_instances_per_group per vesselId\n",
    "        # Define a function to sample or take all if less than max_instances_per_group\n",
    "        def sample_group(group):\n",
    "            if len(group) > max_instances_per_group:\n",
    "                return group.sample(n=max_instances_per_group, random_state=42)\n",
    "            else:\n",
    "                return group\n",
    "\n",
    "        # Apply the sampling function to each group\n",
    "        result = result.groupby('vesselId').apply(sample_group).reset_index(drop=True)\n",
    "\n",
    "        all_test_data = pd.concat([all_test_data, result], ignore_index=True)\n",
    "\n",
    "        prev_shift_length = shift_length\n",
    "        shift_length = int(shift_length**(1.1))\n",
    "        if shift_length == prev_shift_length:\n",
    "            shift_length += 1\n",
    "        print(shift_length)\n",
    "\n",
    "    # Uncomment the line below if you want to remove the \"time\" column after processing\n",
    "    # data = data.drop(\"time\", axis=1)\n",
    "\n",
    "    return all_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'vesselId', 'seconds_to_eta', 'latitude_sin', 'latitude_cos',\n",
      "       'longitude_sin', 'longitude_cos', 'port_latitude_sin',\n",
      "       'port_latitude_cos', 'port_longitude_sin', 'port_longitude_cos',\n",
      "       'cog_sog_sin', 'cog_sog_cos'],\n",
      "      dtype='object')\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "17\n",
      "19\n",
      "22\n",
      "25\n",
      "29\n",
      "34\n",
      "40\n",
      "48\n",
      "58\n",
      "71\n",
      "87\n",
      "108\n",
      "136\n",
      "173\n",
      "223\n",
      "292\n",
      "387\n",
      "521\n"
     ]
    }
   ],
   "source": [
    "print(train_data_preprocessed.columns)\n",
    "\n",
    "train_data_shifted_df = Last_known_location_training_data(\n",
    "    train_data_preprocessed, 400\n",
    ")\n",
    "\n",
    "# train_data_shifted_df = train_data_shifted_df.drop(columns=[\"time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_last_known_data_test(\n",
    "    test_data: pd.DataFrame, known_data: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"_summary_  Groups training data by vesselId, and propogates all data from last known location\n",
    "\n",
    "    Args:\n",
    "    data (_type_): _description_ the data to be altered\n",
    "\n",
    "    Returns:\n",
    "        _type_:? _description_ the altered data\n",
    "    \"\"\"\n",
    "\n",
    "    if not test_data[\"vesselId\"].isin(known_data[\"vesselId\"]).all():\n",
    "        missing_vessels = test_data[\n",
    "            ~test_data[\"vesselId\"].isin(known_data[\"vesselId\"])\n",
    "        ][\"vesselId\"].unique()\n",
    "        raise ValueError(\n",
    "            f\"The following vesselIds are missing in known_data: {missing_vessels}\"\n",
    "        )\n",
    "    print(\n",
    "        test_data[~test_data[\"vesselId\"].isin(known_data[\"vesselId\"])][\n",
    "            \"vesselId\"\n",
    "        ].unique()\n",
    "    )\n",
    "\n",
    "    grouped_data = (\n",
    "        known_data.sort_values(\"time\")\n",
    "        .groupby(\"vesselId\")\n",
    "        .tail(1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    original_time = test_data[[\"time\"]]\n",
    "    test_data = test_data.drop(\"time\", axis=1)\n",
    "\n",
    "    result = pd.merge(test_data, grouped_data, how=\"left\", on=\"vesselId\")\n",
    "\n",
    "    result[\"time_diff\"] = (original_time[\"time\"] - result[\"time\"]).dt.total_seconds()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "   ID                  vesselId  scaling_factor                time  \\\n",
      "0   0  61e9f3aeb937134a3c4bfe3d             0.3 2024-05-07 23:48:16   \n",
      "1   1  61e9f473b937134a3c4c02df             0.3 2024-05-07 23:57:16   \n",
      "2   2  61e9f469b937134a3c4c029b             0.3 2024-05-07 23:59:08   \n",
      "3   3  61e9f45bb937134a3c4c0221             0.3 2024-05-07 23:52:34   \n",
      "4   4  61e9f38eb937134a3c4bfd8d             0.3 2024-05-07 23:51:29   \n",
      "\n",
      "   seconds_to_eta  port_latitude_sin  port_latitude_cos  port_longitude_sin  \\\n",
      "0       -133396.0           0.517228           0.855848           -0.989010   \n",
      "1       -521836.0           0.255732           0.966748            0.863429   \n",
      "2         45952.0           0.619491           0.785004            0.187086   \n",
      "3        -81454.0          -0.688834           0.724919            0.124723   \n",
      "4        101311.0           0.749340           0.662186           -0.106612   \n",
      "\n",
      "   port_longitude_cos  cog_sog_sin  cog_sog_cos  time_diff  last_latitude_sin  \\\n",
      "0            0.147846     0.000000    -0.000000      900.0           0.517228   \n",
      "1           -0.504471     0.000000     0.000000      541.0           0.255732   \n",
      "2            0.982343     2.602537    18.518013      654.0           0.619491   \n",
      "3           -0.992192    -0.062524     0.078043     1080.0          -0.688834   \n",
      "4            0.994301    -0.280074     0.107510     1258.0           0.749340   \n",
      "\n",
      "   last_latitude_cos  last_longitude_sin  last_longitude_cos  \n",
      "0           0.855848           -0.989010            0.147846  \n",
      "1           0.966748            0.863429           -0.504471  \n",
      "2           0.785004            0.187086            0.982343  \n",
      "3           0.724919            0.124723           -0.992192  \n",
      "4           0.662186           -0.106612            0.994301  \n"
     ]
    }
   ],
   "source": [
    "test_data_with_last_known_df = append_last_known_data_test(\n",
    "    test_data, train_data_preprocessed\n",
    ")\n",
    "test_data_with_last_known_df[\n",
    "    [\n",
    "        \"last_latitude_sin\",\n",
    "        \"last_latitude_cos\",\n",
    "        \"last_longitude_sin\",\n",
    "        \"last_longitude_cos\",\n",
    "    ]\n",
    "] = test_data_with_last_known_df[\n",
    "    [\n",
    "        \"latitude_sin\",\n",
    "        \"latitude_cos\",\n",
    "        \"longitude_sin\",\n",
    "        \"longitude_cos\",\n",
    "    ]\n",
    "]\n",
    "test_data_with_last_known_df = test_data_with_last_known_df.drop(\n",
    "    columns=[\n",
    "        \"latitude_sin\",\n",
    "        \"latitude_cos\",\n",
    "        \"longitude_sin\",\n",
    "        \"longitude_cos\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(test_data_with_last_known_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame size: 3.11 GB\n",
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"23.0.1\" 2024-10-15; OpenJDK Runtime Environment Homebrew (build 23.0.1); OpenJDK 64-Bit Server VM Homebrew (build 23.0.1, mixed mode, sharing)\n",
      "  Starting server from /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/7m/94fn3sg96x5fhts9_8f4x63c0000gn/T/tmprzh6zu9j\n",
      "  JVM stdout: /var/folders/7m/94fn3sg96x5fhts9_8f4x63c0000gn/T/tmprzh6zu9j/h2o_iverringheim_started_from_python.out\n",
      "  JVM stderr: /var/folders/7m/94fn3sg96x5fhts9_8f4x63c0000gn/T/tmprzh6zu9j/h2o_iverringheim_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Oslo</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.5</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 11 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_iverringheim_96fpt5</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>5.984 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.0 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       Europe/Oslo\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.5\n",
       "H2O_cluster_version_age:    2 months and 11 days\n",
       "H2O_cluster_name:           H2O_from_python_iverringheim_96fpt5\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    5.984 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.0 final\n",
       "--------------------------  -----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "H2OServerError",
     "evalue": "HTTP 500 Server Error:\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=ISO-8859-1\"/>\n<title>Error 500 java.lang.OutOfMemoryError: Java heap space</title>\n</head>\n<body><h2>HTTP ERROR 500 java.lang.OutOfMemoryError: Java heap space</h2>\n<table>\n<tr><th>URI:</th><td>/3/PostFile</td></tr>\n<tr><th>STATUS:</th><td>500</td></tr>\n<tr><th>MESSAGE:</th><td>java.lang.OutOfMemoryError: Java heap space</td></tr>\n<tr><th>SERVLET:</th><td>water.api.PostFileServlet-207ea13</td></tr>\n<tr><th>CAUSED BY:</th><td>java.lang.OutOfMemoryError: Java heap space</td></tr>\n</table>\n<h3>Caused by:</h3><pre>java.lang.OutOfMemoryError: Java heap space\n\tat water.fvec.UploadFileVec.readPut_impl(UploadFileVec.java:86)\n\tat water.fvec.UploadFileVec.readPut(UploadFileVec.java:61)\n\tat water.fvec.UploadFileVec.readPut(UploadFileVec.java:57)\n\tat water.api.PostFileServlet.doPost(PostFileServlet.java:40)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat water.webserver.jetty9.Jetty9ServerAdapter$LoginHandler.handle(Jetty9ServerAdapter.java:130)\n\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel$$Lambda/0x000001fe013d0640.dispatch(Unknown Source)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.base/java.lang.Thread.runWith(Thread.java:1588)\n</pre>\n\n</body>\n</html>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OServerError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmemory_usage_gb\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m h2o\u001b[38;5;241m.\u001b[39minit(max_mem_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6g\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m train_data_shifted \u001b[38;5;241m=\u001b[39m \u001b[43mh2o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mH2OFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_shifted_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m test_data_with_last_known \u001b[38;5;241m=\u001b[39m h2o\u001b[38;5;241m.\u001b[39mH2OFrame(test_data_with_last_known_df)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m train_data_shifted_df\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/h2o/frame.py:120\u001b[0m, in \u001b[0;36mH2OFrame.__init__\u001b[0;34m(self, python_obj, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns, force_col_types)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ex\u001b[38;5;241m.\u001b[39m_children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m python_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upload_python_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpython_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipped_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_col_types\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/h2o/frame.py:161\u001b[0m, in \u001b[0;36mH2OFrame._upload_python_object\u001b[0;34m(self, python_obj, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns, force_col_types)\u001b[0m\n\u001b[1;32m    159\u001b[0m     csv_writer\u001b[38;5;241m.\u001b[39mwriterows(data_to_write)\n\u001b[1;32m    160\u001b[0m tmp_file\u001b[38;5;241m.\u001b[39mclose()  \u001b[38;5;66;03m# close the streams\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upload_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_strings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mskipped_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_col_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(tmp_path)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/h2o/frame.py:465\u001b[0m, in \u001b[0;36mH2OFrame._upload_parse\u001b[0;34m(self, path, destination_frame, header, sep, column_names, column_types, na_strings, skipped_columns, force_col_types, quotechar, escapechar)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_upload_parse\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, destination_frame, header, sep, column_names, column_types, na_strings, \n\u001b[1;32m    464\u001b[0m                   skipped_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, force_col_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, escapechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 465\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mh2o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST /3/PostFile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m     rawkey \u001b[38;5;241m=\u001b[39m ret[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdestination_frame\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(rawkey, destination_frame, header, sep, column_names, column_types, na_strings, skipped_columns,\n\u001b[1;32m    468\u001b[0m                 force_col_types, quotechar\u001b[38;5;241m=\u001b[39mquotechar, escapechar\u001b[38;5;241m=\u001b[39mescapechar)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/h2o/h2o.py:123\u001b[0m, in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# type checks are performed in H2OConnection class\u001b[39;00m\n\u001b[1;32m    122\u001b[0m _check_connection()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mh2oconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/h2o/backend/connection.py:499\u001b[0m, in \u001b[0;36mH2OConnection.request\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    497\u001b[0m         save_to \u001b[38;5;241m=\u001b[39m save_to(resp)\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_end_transaction(start_time, resp)\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectionError, requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_server \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_server\u001b[38;5;241m.\u001b[39mis_running():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/h2o/backend/connection.py:858\u001b[0m, in \u001b[0;36mH2OConnection._process_response\u001b[0;34m(response, save_to)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m H2OResponseError(data)\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# Server errors (notably 500 = \"Server Error\")\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# Note that it is possible to receive valid H2OErrorV3 object in this case, however it merely means the server\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# did not provide the correct status code.\u001b[39;00m\n\u001b[0;32m--> 858\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m H2OServerError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (status_code, response\u001b[38;5;241m.\u001b[39mreason, data))\n",
      "\u001b[0;31mH2OServerError\u001b[0m: HTTP 500 Server Error:\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=ISO-8859-1\"/>\n<title>Error 500 java.lang.OutOfMemoryError: Java heap space</title>\n</head>\n<body><h2>HTTP ERROR 500 java.lang.OutOfMemoryError: Java heap space</h2>\n<table>\n<tr><th>URI:</th><td>/3/PostFile</td></tr>\n<tr><th>STATUS:</th><td>500</td></tr>\n<tr><th>MESSAGE:</th><td>java.lang.OutOfMemoryError: Java heap space</td></tr>\n<tr><th>SERVLET:</th><td>water.api.PostFileServlet-207ea13</td></tr>\n<tr><th>CAUSED BY:</th><td>java.lang.OutOfMemoryError: Java heap space</td></tr>\n</table>\n<h3>Caused by:</h3><pre>java.lang.OutOfMemoryError: Java heap space\n\tat water.fvec.UploadFileVec.readPut_impl(UploadFileVec.java:86)\n\tat water.fvec.UploadFileVec.readPut(UploadFileVec.java:61)\n\tat water.fvec.UploadFileVec.readPut(UploadFileVec.java:57)\n\tat water.api.PostFileServlet.doPost(PostFileServlet.java:40)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:707)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat water.webserver.jetty9.Jetty9ServerAdapter$LoginHandler.handle(Jetty9ServerAdapter.java:130)\n\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel$$Lambda/0x000001fe013d0640.dispatch(Unknown Source)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.base/java.lang.Thread.runWith(Thread.java:1588)\n</pre>\n\n</body>\n</html>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "memory_usage_bytes = train_data_shifted_df.memory_usage(deep=True).sum()\n",
    "# Convert bytes to gigabytes\n",
    "memory_usage_gb = memory_usage_bytes / (1024 ** 3)\n",
    "# Print the memory usage in gigabytes\n",
    "print(f\"DataFrame size: {memory_usage_gb:.2f} GB\")\n",
    "\n",
    "h2o.init(max_mem_size=\"6g\")\n",
    "\n",
    "train_data_shifted = h2o.H2OFrame(train_data_shifted_df)\n",
    "test_data_with_last_known = h2o.H2OFrame(test_data_with_last_known_df)\n",
    "\n",
    "del train_data_shifted_df\n",
    "del test_data_with_last_known_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_shifted_without_validation, validation_data_shifted = (\n",
    "    train_data_shifted.split_frame(ratios=[0.9], seed=42)   \n",
    ")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lat = [\n",
    "    # \"vesselId\",\n",
    "    \"cog_sog_sin\",\n",
    "    \"cog_sog_cos\",\n",
    "    #\"rot\",\n",
    "    # \"heading_sin\",\n",
    "    # \"heading_cos\",\n",
    "    # \"navstat\",\n",
    "    #\"shippingLineId\",\n",
    "    \"time_diff\",\n",
    "    \"seconds_to_eta\",\n",
    "    \"last_latitude_sin\",\n",
    "    \"last_latitude_cos\",\n",
    "    \"last_longitude_sin\",\n",
    "    \"last_longitude_cos\",\n",
    "    \"port_latitude_sin\",\n",
    "    \"port_latitude_cos\",\n",
    "    \"port_longitude_sin\",\n",
    "    \"port_longitude_cos\",\n",
    "    # \"hour_sin\",\n",
    "    # \"hour_cos\",\n",
    "    #\"day_sin\",\n",
    "    #\"day_cos\",\n",
    "    # \"month_sin\",\n",
    "    # \"month_cos\",\n",
    "]\n",
    "features_long = [\n",
    "    # \"vesselId\",\n",
    "    \"cog_sog_sin\",\n",
    "    \"cog_sog_cos\",\n",
    "    #\"rot\",\n",
    "    #\"shippingLineId\",\n",
    "    # \"heading_sin\",\n",
    "    # \"heading_cos\",\n",
    "    # \"navstat\",\n",
    "    \"time_diff\",\n",
    "    \"seconds_to_eta\",\n",
    "    \"last_latitude_sin\",\n",
    "    \"last_latitude_cos\",\n",
    "    \"last_longitude_sin\",\n",
    "    \"last_longitude_cos\",\n",
    "    \"port_latitude_sin\",\n",
    "    \"port_latitude_cos\",\n",
    "    \"port_longitude_sin\",\n",
    "    \"port_longitude_cos\",\n",
    "    # \"hour_sin\",\n",
    "    # \"hour_cos\",\n",
    "    #\"day_sin\",\n",
    "    #\"day_cos\",\n",
    "    # \"month_sin\",\n",
    "    # \"month_cos\",\n",
    "    \"latitude_sin\",\n",
    "    \"latitude_cos\",\n",
    "]\n",
    "target_long_sin = \"longitude_sin\"\n",
    "target_long_cos = \"longitude_cos\"\n",
    "target_lat_sin = \"latitude_sin\"\n",
    "target_lat_cos = \"latitude_cos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lat_sin = {\n",
    "    'ntrees': 150,\n",
    "    'max_depth': 20,\n",
    "    'min_rows': 5,\n",
    "    'mtries': -1,\n",
    "    'sample_rate': 0.7,\n",
    "    'col_sample_rate_per_tree': 0.8,\n",
    "    'stopping_rounds': 5,\n",
    "    'stopping_metric': \"AUTO\",\n",
    "    'stopping_tolerance': 0.001,\n",
    "    'seed': 42\n",
    "}\n",
    "params_lat_cos = {\n",
    "    'ntrees': 150,\n",
    "    'max_depth': 20,\n",
    "    'min_rows': 5,\n",
    "    'mtries': -1,\n",
    "    'sample_rate': 0.7,\n",
    "    'col_sample_rate_per_tree': 0.8,\n",
    "    'stopping_rounds': 5,\n",
    "    'stopping_metric': \"AUTO\",\n",
    "    'stopping_tolerance': 0.001,\n",
    "    'seed': 42\n",
    "}\n",
    "params_long_sin = {\n",
    "    'ntrees': 150,\n",
    "    'max_depth': 20,\n",
    "    'min_rows': 5,\n",
    "    'mtries': -1,\n",
    "    'sample_rate': 0.7,\n",
    "    'col_sample_rate_per_tree': 0.8,\n",
    "    'stopping_rounds': 5,\n",
    "    'stopping_metric': \"AUTO\",\n",
    "    'stopping_tolerance': 0.001,\n",
    "    'seed': 42\n",
    "}\n",
    "params_long_cos = {\n",
    "    'ntrees': 150,\n",
    "    'max_depth': 20,\n",
    "    'min_rows': 5,\n",
    "    'mtries': -1,\n",
    "    'sample_rate': 0.7,\n",
    "    'col_sample_rate_per_tree': 0.8,\n",
    "    'stopping_rounds': 5,\n",
    "    'stopping_metric': \"AUTO\",\n",
    "    'stopping_tolerance': 0.001,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "drf_lat_sin = h2o.estimators.H2ORandomForestEstimator(**params_lat_sin)\n",
    "drf_lat_cos = h2o.estimators.H2ORandomForestEstimator(**params_lat_cos)\n",
    "drf_long_sin = h2o.estimators.H2ORandomForestEstimator(**params_long_sin)\n",
    "drf_long_cos = h2o.estimators.H2ORandomForestEstimator(**params_long_cos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    \"drf_lat_sin\": {\n",
    "        \"model\": drf_lat_sin,\n",
    "        \"features\": features_lat,\n",
    "        \"target\": target_lat_sin,\n",
    "    },\n",
    "    \"drf_lat_cos\": {\n",
    "        \"model\": drf_lat_cos,\n",
    "        \"features\": features_lat,\n",
    "        \"target\": target_lat_cos,\n",
    "    },\n",
    "    \"drf_long_sin\": {\n",
    "        \"model\": drf_long_sin,\n",
    "        \"features\": features_long,  # Ensure features_long is defined\n",
    "        \"target\": target_long_sin,\n",
    "    },\n",
    "    \"drf_long_cos\": {\n",
    "        \"model\": drf_long_cos,\n",
    "        \"features\": features_long,  # Ensure features_long is defined\n",
    "        \"target\": target_long_cos,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drf_lat_sin.train(\n",
    "    x=features_lat,  # .append(latitude_sin)\n",
    "    y=target_lat_sin,\n",
    "    training_frame=train_data_shifted_without_validation,\n",
    "    validation_frame=validation_data_shifted,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drf_lat_cos.train(\n",
    "    x=features_lat,  # .append(latitude_sin)\n",
    "    y=target_lat_cos,\n",
    "    training_frame=train_data_shifted_without_validation,\n",
    "    validation_frame=validation_data_shifted,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_lat_sin = drf_lat_sin.model_performance(test_data=validation_data_shifted, train_data=train_data_shifted_without_validation)\n",
    "performance_lat_cos = drf_lat_cos.model_performance(test_data=validation_data_shifted,train_data=train_data_shifted_without_validation)\n",
    "\n",
    "\n",
    "# Print the performance metrics\n",
    "print(performance_lat_sin)\n",
    "print(performance_lat_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drf_long_sin.train(\n",
    "    x=features_long,\n",
    "    y=target_long_sin,\n",
    "    training_frame=train_data_shifted_without_validation,\n",
    "    validation_frame=validation_data_shifted,\n",
    ")\n",
    "#MSE: 0.00023605270678827214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drf_long_cos.train(\n",
    "    x=features_long,  # .append(\"longitude_sin\")\n",
    "    y=target_long_cos,\n",
    "    training_frame=train_data_shifted_without_validation,\n",
    "    validation_frame=validation_data_shifted,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_long_sin = drf_long_sin.model_performance(test_data=validation_data_shifted)\n",
    "performance_long_cos = drf_long_cos.model_performance(test_data=validation_data_shifted)\n",
    "\n",
    "print(performance_long_sin)\n",
    "print(performance_long_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_with_predicted_lat = test_data_with_last_known\n",
    "\n",
    "lat_predictions_sin = drf_lat_sin.predict(test_data_with_last_known)\n",
    "test_data_with_last_known[\"latitude_sin\"] = lat_predictions_sin\n",
    "lat_predictions_cos = drf_lat_cos.predict(test_data_with_last_known)\n",
    "test_data_with_predicted_lat[\"latitude_cos\"] = lat_predictions_cos\n",
    "\n",
    "test_data_with_predicted_lat[\"latitude_sin\"] = lat_predictions_sin\n",
    "test_data_with_predicted_lat[\"latitude_cos\"] = lat_predictions_cos\n",
    "\n",
    "long_predictions_sin = drf_long_sin.predict(test_data_with_predicted_lat)\n",
    "test_data_with_last_known[\"longitude_sin\"] = long_predictions_sin\n",
    "long_predictions_cos = drf_long_cos.predict(test_data_with_predicted_lat)\n",
    "test_data_with_last_known[\"longitude_cos\"] = long_predictions_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sine and cosine values back to radians\n",
    "lat_predictions_sin = lat_predictions_sin.as_data_frame()\n",
    "lat_predictions_cos = lat_predictions_cos.as_data_frame()\n",
    "long_predictions_sin = long_predictions_sin.as_data_frame()\n",
    "long_predictions_cos = long_predictions_cos.as_data_frame()\n",
    "\n",
    "\n",
    "lat_predictions_radians = np.arctan2(lat_predictions_sin, lat_predictions_cos)\n",
    "long_predictions_radians = np.arctan2(long_predictions_sin, long_predictions_cos)\n",
    "\n",
    "# Convert radians to degrees\n",
    "lat_predictions_degrees = np.rad2deg(lat_predictions_radians)\n",
    "long_predictions_degrees = np.rad2deg(long_predictions_radians)\n",
    "\n",
    "# Print the first few rows to verify the conversion\n",
    "print(lat_predictions_degrees.head())\n",
    "print(long_predictions_degrees.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prediction_visualization_data(validation_data):\n",
    "    lat_val_sin = drf_lat_sin.predict(validation_data)\n",
    "    lat_val_cos = drf_lat_cos.predict(validation_data)\n",
    "    long_val_sin = drf_long_sin.predict(validation_data)\n",
    "    long_val_cos = drf_long_cos.predict(validation_data)\n",
    "\n",
    "    lat_val_sin = lat_val_sin.as_data_frame()\n",
    "    lat_val_cos = lat_val_cos.as_data_frame()\n",
    "    long_val_sin = long_val_sin.as_data_frame()\n",
    "    long_val_cos = long_val_cos.as_data_frame()\n",
    "\n",
    "    validation_data = validation_data.as_data_frame()\n",
    "\n",
    "    lat_val_radians = np.arctan2(lat_val_sin, lat_val_cos)\n",
    "    long_val_radians = np.arctan2(long_val_sin, long_val_cos)\n",
    "\n",
    "    evaluation_lat_radians = np.arctan2(\n",
    "        validation_data[\"latitude_sin\"], validation_data[\"latitude_cos\"]\n",
    "    )\n",
    "    evaluation_long_radians = np.arctan2(\n",
    "        validation_data[\"longitude_sin\"], validation_data[\"longitude_cos\"]\n",
    "    )\n",
    "\n",
    "    # Convert radians to degrees\n",
    "    lat_val_degrees = np.rad2deg(lat_val_radians)\n",
    "    long_val_degrees = np.rad2deg(long_val_radians)\n",
    "\n",
    "    evaluation_lat_degrees = np.rad2deg(evaluation_lat_radians)\n",
    "    evaluation_long_degrees = np.rad2deg(evaluation_long_radians)\n",
    "\n",
    "    eval_predictions = pd.concat([lat_val_degrees, long_val_degrees], axis=1)\n",
    "\n",
    "    eval_actual = pd.concat([evaluation_lat_degrees, evaluation_long_degrees], axis=1)\n",
    "\n",
    "    eval_predictions.columns = [\"latitude_predicted\", \"longitude_predicted\"]\n",
    "    eval_actual.columns = [\"latitude\", \"longitude\"]\n",
    "\n",
    "    eval = pd.DataFrame()\n",
    "    eval[[\"latitude_predicted\", \"longitude_predicted\"]] = eval_predictions\n",
    "    eval[[\"latitude\", \"longitude\"]] = eval_actual\n",
    "    eval[[\"vesselId\", \"time\"]] = validation_data[[\"vesselId\", \"time\"]]\n",
    "    eval.to_csv(\"eval_predictions.csv\")\n",
    "\n",
    "\n",
    "# create_prediction_visualization_data(validation_data_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat([lat_predictions_degrees, long_predictions_degrees], axis=1)\n",
    "predictions.columns = [\"latitude_predicted\", \"longitude_predicted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"ID\"] = test_data[\"ID\"]\n",
    "predictions = predictions[[\"ID\", \"longitude_predicted\", \"latitude_predicted\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"drf_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
